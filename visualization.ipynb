{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sealed-missile",
   "metadata": {},
   "source": [
    "### 0. Introduction\n",
    "This ipynb file is to instruct how to visualize the results of analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-rates",
   "metadata": {},
   "source": [
    "### 1. Color settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, f1_score, roc_auc_score, auc, precision_recall_curve\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib as mpl\n",
    "#return manually defined colormap\n",
    "\n",
    "def generate_cmap(colors):\n",
    "    values = range(len(colors))\n",
    "\n",
    "    vmax = np.ceil(np.max(values))\n",
    "    color_list = []\n",
    "    for v, c in zip(values, colors):\n",
    "        color_list.append( ( v/ vmax, c) )\n",
    "    return LinearSegmentedColormap.from_list('custom_cmap', color_list)\n",
    "\n",
    "clist_darkblue = ['#475267', '#63728e', '#8895ac', '#b0b8c8', '#d7dce3', '#f3f4f7']\n",
    "clist_green = ['#49812f', '#579b38', '#79c257', '#a2d58b', '#c7e6b9']\n",
    "clist_red = ['#F16262', '#f18a7c', '#F1B296', '#f1c7b7', '#F1DDD9']\n",
    "\n",
    "clist_powerpoint = ['#475468', '#8797AD', '#AECCD4', '#F3F8F9']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2,4,figsize=(20,10))\n",
    "x = np.linspace(0,10,11)\n",
    "for i in range(len(clist_darkblue)):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[0,0].plot(x, y, marker='o', linestyle='-', color=clist_darkblue[i])\n",
    "\n",
    "for i in range(len(clist_powerpoint)):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[0,1].plot(x, y, marker='o', linestyle='-', color=clist_powerpoint[i])\n",
    "    \n",
    "for i in range(len(clist_green)):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[0,2].plot(x, y, marker='o', linestyle='-', color=clist_green[i])\n",
    "    \n",
    "for i in range(len(clist_red)):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[0,3].plot(x, y, marker='o', linestyle='-', color=clist_red[i])\n",
    "\n",
    "clist_winter = []\n",
    "cmap_winter = plt.get_cmap('winter',10)\n",
    "for i in range(cmap_winter.N):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[1,0].plot(x, y, marker='o', linestyle='-', color=cmap_winter(i))\n",
    "    clist_winter.append(cmap_winter(i)[:-1])\n",
    "\n",
    "clist_ocean = []\n",
    "cmap_ocean = plt.get_cmap('ocean',15)\n",
    "for i in range(cmap_ocean.N):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[1,1].plot(x, y, marker='o', linestyle='-', color=cmap_ocean(i))\n",
    "    clist_ocean.append(cmap_ocean(i)[:-1])\n",
    "\n",
    "clist_gnbu = []\n",
    "cmap_gnbu = plt.get_cmap('GnBu',15)\n",
    "for i in range(cmap_gnbu.N):\n",
    "    y = np.full(len(x), i)\n",
    "    ax[1,2].plot(x, y, marker='o', linestyle='-', color=cmap_gnbu(i))\n",
    "    clist_gnbu.append(cmap_gnbu(i)[:-1])\n",
    "\n",
    "#bert_kmer_colors = np.array(clist_ocean[10:14][::-1])\n",
    "#bert_kmer_swarms = np.tile(clist_powerpoint[0], 4)\n",
    "bert_models_colors = [clist_gnbu[6],clist_gnbu[7], clist_gnbu[8], clist_gnbu[9], clist_ocean[10]]\n",
    "bert_models_swarms = np.tile(clist_powerpoint[0], 5)\n",
    "#print(np.array(clist_ocean[10]) * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_custom_colormap(name: str, color_list: list):\n",
    "\n",
    "    cmap_dis = mpl.colors.ListedColormap(color_list)\n",
    "    cmap_seq = mpl.colors.LinearSegmentedColormap.from_list(name, color_list)\n",
    "\n",
    "    plt.register_cmap(name + '_dis', cmap_dis)\n",
    "    plt.register_cmap(name + '_dis_r', cmap_dis.reversed())\n",
    "    plt.register_cmap(name + '_seq', cmap_seq)\n",
    "    plt.register_cmap(name + '_seq_r', cmap_seq.reversed())\n",
    "    return\n",
    "\n",
    "COLORMAP_SOURCE_DICT = {\n",
    "\n",
    "    'bertrbp_single_graphprot': ['#FFFFFF', '#a3f5f5'], #light blue\n",
    "    'bertrbp_single_ideepS': ['#FFFFFF', '#f4e7b2'], #cream yellow\n",
    "    'bertrbp_single_hocnnlb': ['#FFFFFF', '#95D6BB'], #faded green\n",
    "    'bertrbp_single_baseline': ['#bff9f9','#FFFFFF','#F16262'], #red f47f7f\n",
    "    #'bertrbp_single_bertrbp': ['#e8a38c', '#f7e0d9','#FFFFFF', '#2083a4', '#175e75'], #blue 3db2d9\n",
    "    'bertrbp_single_bertrbp': ['#adb9ca','#fcfcfc', '#fb5d0e'], #blue 3db2d9\n",
    "    'bertrbp_single_bertbaseline': ['#adb9ca','#fcfcfc', '#50d284'], #blue 3db2d9\n",
    "    #'bertrbp_single_bertrbp_corr': ['#b2e0f0','#fcfcfc', '#F16262'], #blue 3db2d9\n",
    "    'bertrbp_single_bertrbp_corr': ['#93cee1','#fcfcfc', '#e86868'], #blue 3db2d9\n",
    "    'bertrbp_single_bertrbp2': ['#fcfcfc', '#fb5d0e'], #blue 3db2d9\n",
    "    'bertrbp_single_bertrbp3': ['#fcfcfc', '#44546a'], #blue 3db2d9\n",
    "    'bertrbp_single_dnabert': ['#e0b4d8', '#FFFFFF', '#47ad59'], #green 54B967\n",
    "\n",
    "    'bertrbp_accent': ['#51a0c8', '#5ea77e', '#9ff9f9', '#89e1ac', '#fc8b52', '#FFFFFF'],\n",
    "    'bertrbp_accent2': ['#f4e7b2', '#95D6BB', '#f47f7f', '#3db2d9', '#47ad59', '#FFFFFF'],\n",
    "    \n",
    "}\n",
    "\n",
    "# colormap\n",
    "for name, color_list in COLORMAP_SOURCE_DICT.items():\n",
    "    set_custom_colormap(name, color_list)\n",
    "\n",
    "\n",
    "DEFAULT_COLORMAP = 'bertrbp_accent_dis'\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette(DEFAULT_COLORMAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-springer",
   "metadata": {},
   "source": [
    "### 2. Visualize region type analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASTER_DIR = \"./datasets\"\n",
    "MASTER_DIR = \"./sample_dataset\"\n",
    "rbps = ('TIAL1',)\n",
    "regiontypes = (\"5'UTR\", \"3'UTR\", \"intron\", \"CDS\")\n",
    "index_regiontypes = {\"5'UTR\":0, \"3'UTR\":1, \"intron\":3, \"CDS\":4}\n",
    "SUBDIR = \"finetuned_model/analyze_regiontype\"\n",
    "SUBDIR_BASELINE = \"finetuned_model_baseline/analyze_regiontype\" # if you have trained the BERT-baseline\n",
    "VISUALIZE = True\n",
    "selected_heads = []\n",
    "\n",
    "ax_i = len(rbps)\n",
    "if ax_i < 2:\n",
    "    ax_i = 1\n",
    "ax_j = len(regiontypes)\n",
    "heatmap_xlabels = list(map(int, np.linspace(1,12,12)))\n",
    "heatmap_ylabels = heatmap_xlabels[::-1]\n",
    "\n",
    "for rbp in rbps:\n",
    "    fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*8, ax_i*6.4))\n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regiontype_type0.npy\")\n",
    "    regiontype_matrix = np.load(filename)\n",
    "    for num_region, regiontype in enumerate(regiontypes):\n",
    "        index = index_regiontypes[regiontype]\n",
    "        sns.heatmap(np.flip(regiontype_matrix[index], axis=0), ax =ax[num_region],\\\n",
    "                            center=1.0, cmap='bertrbp_single_bertrbp_seq')\n",
    "        ax[num_region].set_xlabel(\"Head\", fontsize=18, labelpad=8)\n",
    "        ax[num_region].set_ylabel(\"Layer\", fontsize=18, labelpad=8)\n",
    "        ax[num_region].set_xticklabels(heatmap_xlabels)\n",
    "        ax[num_region].set_yticklabels(heatmap_ylabels)\n",
    "        ax[num_region].tick_params(axis = 'x', labelsize =18)\n",
    "        ax[num_region].tick_params(axis = 'y', labelsize =18, rotation=0)\n",
    "        ax[num_region].set_title(\"{} BERT-RBP : {}\".format(rbp, regiontype), fontsize=24, x=0.5, y=1.02)\n",
    "        fig.patch.set_alpha(0)\n",
    "        fig.savefig(\"heatmap_regiontype_specific_{}_{}.eps\".format(rbp, regiontype), dpi=350)\n",
    "    \n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR_BASELINE, \"analyze_regiontype_type0.npy\")\n",
    "    if os.path.exists(filename):\n",
    "        fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*8, ax_i*6.4))\n",
    "        for num_region, regiontype in enumerate(regiontypes):\n",
    "            regiontype_matrix = np.load(filename)\n",
    "            index = index_regiontypes[regiontype]\n",
    "            sns.heatmap(np.flip(regiontype_matrix[index], axis=0), ax =ax[num_region],\\\n",
    "                                center=1.0, cmap='bertrbp_single_bertbaseline_seq')\n",
    "            ax[num_region].set_xlabel(\"Head\", fontsize=18, labelpad=8)\n",
    "            ax[num_region].set_ylabel(\"Layer\", fontsize=18, labelpad=8)\n",
    "            ax[num_region].set_xticklabels(heatmap_xlabels)\n",
    "            ax[num_region].set_yticklabels(heatmap_ylabels)\n",
    "            ax[num_region].tick_params(axis = 'x', labelsize =18)\n",
    "            ax[num_region].tick_params(axis = 'y', labelsize =18, rotation=0)\n",
    "            ax[num_region].set_title(\"{} BERT-baseline : {}\".format(rbp, regiontype), fontsize=24, x=0.5, y=1.02)\n",
    "            fig.patch.set_alpha(0)\n",
    "            fig.savefig(\"heatmap_regiontype_specific_{}_{}_baseline.eps\".format(rbp, regiontype), dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-partition",
   "metadata": {},
   "source": [
    "### 3. Visualize region type analysis (in detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "#MASTER_DIR = \"./datasets\"\n",
    "MASTER_DIR = \"./sample_dataset\"\n",
    "'''\n",
    "rbps = ('FUS', 'SRSF1',\\\n",
    "        'QKI', 'IGF2BP1', 'IGF2BP2', 'IGF2BP3', 'U2AF2',\\\n",
    "       'TAF15', 'HNRNPC',\\\n",
    "        'HNRNPL', 'TIAL1', 'TIA1',\\\n",
    "        'EWSR1', 'NSUN2', 'PUM2')\n",
    "'''\n",
    "rbps=('TIAL1',)\n",
    "rbps = sorted(rbps)\n",
    "rbps_not_yet = ()\n",
    "regiontypes = (\"5'UTR\", \"3'UTR\", \"intron\", \"CDS\")\n",
    "index_regiontypes = {\"5'UTR\":0, \"3'UTR\":1, \"intron\":3, \"CDS\":4}\n",
    "SUBDIR = \"finetuned_model/analyze_regiontype\"\n",
    "VISUALIZE = True\n",
    "NUM_BINS = 15\n",
    "SEQ_LENGTH = 101\n",
    "VOLUME_PERCENT = 0.995\n",
    "PLOTSTYLE = \"barplot\"\n",
    "NUM_SPLIT=3\n",
    "\n",
    "ax_i = len(rbps)\n",
    "ax_j = len(regiontypes)\n",
    "\n",
    "\n",
    "spearmans = []\n",
    "for num_rbp, rbp in enumerate(rbps):        \n",
    "    fig, ax = plt.subplots(1, ax_j, figsize=(ax_j*8, 6))    \n",
    "    spearman = []\n",
    "    textfile = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regiontype.txt\")\n",
    "    regions_and_heads = []\n",
    "    with open(textfile, 'r') as f:\n",
    "        for line in f:\n",
    "            region_and_head = []\n",
    "            if re.match(\"region_type: [0-9a-zA-Z\\']+, max_head: [0-9\\-]+\", line):\n",
    "                for regiontype in regiontypes:\n",
    "                    if regiontype in line:\n",
    "                        region_and_head.append(index_regiontypes[regiontype]+1)\n",
    "                        max_head = re.findall(\"max_head: [0-9\\-]+\", line)[0]\n",
    "                        max_head = [int(i) for i in re.findall(\"[0-9]+\", max_head)]\n",
    "                        region_and_head.extend(max_head)\n",
    "                        regions_and_heads.append(region_and_head)\n",
    "    #regions_and_heads = [[1,9,1],[2,9,11],[4,12,4],[5,12,4]] \n",
    "    for num_region, regiontype in enumerate(regiontypes):\n",
    "        for num_maxmin, maxmin in enumerate([\"max\"]):\n",
    "            region, layer, head = regions_and_heads[num_region]\n",
    "            \n",
    "            filename = \"analyze_regiontype_specific_type{}_layer{}_head{}.tsv\".format(region, layer, head)\n",
    "            path = os.path.join(MASTER_DIR, rbp, SUBDIR, filename)\n",
    "            regiontype_vs_attention = pd.read_csv(path, sep=\"\\t\")\n",
    "\n",
    "            i = num_rbp\n",
    "            j = num_region\n",
    "            sns.set()\n",
    "            sns.set_style('whitegrid')\n",
    "            sns.despine()\n",
    "            color = \"#2492b6\"\n",
    "            if num_maxmin == 1:\n",
    "                color = \"#F16262\"\n",
    "            \n",
    "            if PLOTSTYLE==\"barplot\":\n",
    "                q_low = 0\n",
    "                q_high = VOLUME_PERCENT\n",
    "                quantiles = regiontype_vs_attention[\"attention\"].quantile([q_low, q_high])\n",
    "                \n",
    "                attention_max = quantiles[q_high]\n",
    "                attention_min = quantiles[q_low]                \n",
    "                attention_thresh = np.linspace(attention_min, attention_max, NUM_BINS+1)\n",
    "                \n",
    "                background_x = [attention_min, attention_max]\n",
    "                background_y = [np.mean(np.array(regiontype_vs_attention)[:,0])/SEQ_LENGTH,\\\n",
    "                                np.mean(np.array(regiontype_vs_attention)[:,0])/SEQ_LENGTH]\n",
    "\n",
    "                y_value = np.zeros([NUM_SPLIT, NUM_BINS])\n",
    "                fracs = np.linspace(0,1,NUM_SPLIT+1) * len(regiontype_vs_attention)\n",
    "                fracs = list(map(int, fracs))\n",
    "                for num_split, frac in enumerate(fracs[1:]):\n",
    "                    frac = frac - fracs[num_split]\n",
    "                    len_df_data = len(regiontype_vs_attention)\n",
    "                    df_data_split = 0\n",
    "                    if num_split==NUM_SPLIT-1:\n",
    "                        df_data_split = regiontype_vs_attention\n",
    "                    else:\n",
    "                        df_data_split = regiontype_vs_attention.sample(n=frac, random_state=0)\n",
    "                    regiontype_vs_attention = regiontype_vs_attention.drop(df_data_split.index)\n",
    "                    df_data_split = np.array(df_data_split)\n",
    "                    \n",
    "                    regiontype_values = np.zeros([NUM_BINS])\n",
    "                    count = np.zeros([NUM_BINS])\n",
    "                    for data_point in df_data_split:\n",
    "                        for bins in range(1, len(attention_thresh)):\n",
    "                            if bins==1 and data_point[1] >= attention_thresh[bins-1] and data_point[1] <=attention_thresh[bins]:\n",
    "                                regiontype_values[bins-1] += data_point[0]\n",
    "                                count[bins-1] += 1\n",
    "                            elif data_point[1] > attention_thresh[bins-1] and data_point[1] <=attention_thresh[bins]:\n",
    "                                regiontype_values[bins-1] += data_point[0]\n",
    "                                count[bins-1] += 1\n",
    "                    y_value[num_split] = regiontype_values / count / SEQ_LENGTH\n",
    "                y_err = np.std(y_value, axis=0)\n",
    "                y_value = np.mean(y_value, axis=0)\n",
    "                \n",
    "                spearman.append(spearmanr(attention_thresh[:-1], y_value))\n",
    "\n",
    "                # print(count)\n",
    "                # print(regiontype_values)\n",
    "                \n",
    "                if NUM_SPLIT==1:\n",
    "                    ax[j].bar(attention_thresh[:-1], y_value, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")#e7a888\n",
    "                else:\n",
    "                    ax[j].bar(attention_thresh[:-1], y_value, yerr=y_err, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")\n",
    "                ax[j].plot(background_x, background_y, '--', label=\"background\", color=\"#475267\")\n",
    "                ax[j].set_ylabel(\"Region probability\", fontsize=18, labelpad=6)\n",
    "            elif PLOTSTYLE==\"scatterplot\":\n",
    "                regiontype_vs_attention = np.array(regiontype_vs_attention)\n",
    "                ax[j].plot(regiontype_vs_attention[:,1], regiontype_vs_attention[:,0], 'o', color=color)\n",
    "                ax[j].set_ylabel(\"region value\")\n",
    "            \n",
    "            ax[j].set_xlabel(\"Raw attention to CLS\", fontsize=18, labelpad=6)\n",
    "            ax[j].set_title(\"{} {} : head {}-{}\".format(rbp, regiontypes[num_region], layer, head), fontsize=20, x=0.5, y=1.03)\n",
    "            plt.xticks(fontsize =16)\n",
    "            plt.yticks(fontsize =16)\n",
    "            \n",
    "    fig.patch.set_alpha(0)\n",
    "    fig.savefig(\"graph_regiontype_{}.eps\".format(rbp), dpi=350)\n",
    "    spearmans.append(spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-perspective",
   "metadata": {},
   "source": [
    "### 4. Visualize region boundary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASTER_DIR = \"./datasets\"\n",
    "MASTER_DIR = \"./sample_dataset\"\n",
    "MASTER_DIR_DNABERT = \"../3-new-12w-0/\"\n",
    "#rbps = ('EWSR1', 'TIA1','SRSF1','IGF2BP1', 'IGF2BP2','IGF2BP3',\"HNRNPL\",\"NSUN2\", \"PUM2\",'TIAL1', 'TAF15', 'U2AF2')\n",
    "rbps = ('EWSR1',)\n",
    "rbps = sorted(rbps)\n",
    "regiontypes = (\"5'UTR\", \"3'UTR\", \"exon\", \"intron\", \"CDS\", \"outside\")\n",
    "regionboundaries = [[1,4],[0,4],[3,4],[0,3],[1,3]]\n",
    "SUBDIR = \"finetuned_model/analyze_regionboundary\"\n",
    "SUBDIR_DNABERT = \"analyze_regionboundary\"\n",
    "VISUALIZE = True\n",
    "selected_heads = []\n",
    "\n",
    "ax_i = 2\n",
    "ax_j = len(regionboundaries)\n",
    "fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*8, ax_i*6.4))\n",
    "heatmap_xlabels = list(map(int, np.linspace(1,12,12)))\n",
    "heatmap_ylabels = heatmap_xlabels[::-1]\n",
    "\n",
    "for num_rbp, rbp in enumerate(rbps):\n",
    "    print(rbp)\n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regionboundary_all2.npy\")\n",
    "    filename2 = os.path.join(MASTER_DIR_DNABERT, rbp, SUBDIR_DNABERT, \"analyze_regionboundary_all2.npy\")\n",
    "    \n",
    "    regiontype_matrix = np.load(filename)\n",
    "    if os.path.exists(filename2):\n",
    "        regiontype_matrix2 = np.load(filename2)\n",
    "    \n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regionboundary_count_all.npy\")\n",
    "    counts = np.load(filename)\n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regionboundary_count_negative_all.npy\")\n",
    "    counts = counts / np.load(filename)\n",
    "    \n",
    "    if os.path.exists(filename2):\n",
    "        filename = os.path.join(MASTER_DIR_DNABERT, rbp, SUBDIR_DNABERT, \"analyze_regionboundary_count_all.npy\")\n",
    "        counts2 = np.load(filename)\n",
    "        filename = os.path.join(MASTER_DIR_DNABERT, rbp, SUBDIR_DNABERT, \"analyze_regionboundary_count_negative_all.npy\")\n",
    "        counts2 = counts2 / np.load(filename)\n",
    "    \n",
    "    #print(regiontype_matrix.shape)\n",
    "    max_heads = []\n",
    "    for num_boundary, regionboundary in enumerate(regionboundaries):\n",
    "        region1 = regiontypes[regionboundary[0]]\n",
    "        region2 = regiontypes[regionboundary[1]]\n",
    "        \n",
    "        max_val = np.max(regiontype_matrix[num_boundary])\n",
    "        max_heads.append((np.where(regiontype_matrix[num_boundary]==max_val)[0][0]+1, np.where(regiontype_matrix[num_boundary]==max_val)[1][0]+1))\n",
    "\n",
    "        if VISUALIZE:\n",
    "            sns.heatmap(np.flip(regiontype_matrix[num_boundary], axis=0), ax =ax[1, num_boundary],\\\n",
    "                        cmap=\"bertrbp_single_bertrbp_seq\", center=counts[num_boundary])\n",
    "            ax[1, num_boundary].set_xlabel(\"Head\", fontsize=18, labelpad=8)\n",
    "            if num_boundary==0:\n",
    "                ax[1, num_boundary].set_ylabel(\"Layer\", fontsize=18, labelpad=8)\n",
    "            ax[1, num_boundary].set_xticklabels(heatmap_xlabels, fontsize=18)\n",
    "            ax[1, num_boundary].set_yticklabels(heatmap_ylabels, fontsize=18, rotation=0)\n",
    "            #ax[1, num_boundary].set_title(\"{} BERT-RBP : {} and {}\".format(rbp, region1, region2), fontsize=20, x=0.5, y=1.02)\n",
    "        \n",
    "        if VISUALIZE and os.path.exists(filename2):\n",
    "            sns.heatmap(np.flip(regiontype_matrix2[num_boundary], axis=0), ax =ax[0, num_boundary],\\\n",
    "                        cmap=\"bertrbp_single_bertdnabert_seq\", center=counts[num_boundary])\n",
    "            #ax[0, num_boundary].set_xlabel(\"Head\", fontsize=18, labelpad=8)\n",
    "            if num_boundary==0:\n",
    "                ax[0, num_boundary].set_ylabel(\"Layer\", fontsize=18, labelpad=8)\n",
    "            ax[0, num_boundary].set_xticklabels(heatmap_xlabels, fontsize=18)\n",
    "            ax[0, num_boundary].set_yticklabels(heatmap_ylabels, fontsize=18, rotation=0)\n",
    "            #ax[0, num_boundary].set_title(\"{} DNABERT : {} and {}\".format(rbp, region1, region2), fontsize=20, x=0.5, y=1.02)\n",
    "            ax[0, num_boundary].set_title(\"{} : {} and {}\".format(rbp, region1, region2), fontsize=20, x=0.5, y=1.02)\n",
    "        fig.subplots_adjust(hspace=0.15, wspace=0.15)\n",
    "        fig.patch.set_alpha(0)\n",
    "        #fig.savefig(\"heatmap_regionboundary_{}_{}-{}.eps\".format(rbp, region1, region2), dpi=350)\n",
    "    fig.savefig(\"heatmap_regionboundary_{}.eps\".format(rbp), dpi=350)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-elements",
   "metadata": {},
   "source": [
    "### 5. Visualize region boundary analysis (in detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_all = {\"EWSR1\": ((5, 11), (10, 11), (6, 8)),\n",
    "             \"HNRNPL\": ((5, 11), (4, 1), (6, 8)),\n",
    "             \"IGF2BP1\": ((6, 8), (3, 9), (3, 3)),\n",
    "             \"IGF2BP2\": ((5, 11), (12, 4), (3, 3)),\n",
    "             \"IGF2BP3\": ((6, 8), (10, 11), (3, 3)),\n",
    "             \"NSUN2\": ((3, 3), (10, 11), (6, 8)),\n",
    "             \"PUM2\": ((5, 11), (11, 1), (3, 1)),\n",
    "             \"SRSF1\": ((5, 11), (10, 11), (3, 1), (6, 8)),\n",
    "             \"TIA1\": ((6, 8), (3, 9), (3, 3))}\n",
    "\n",
    "#RBPS=(\"EWSR1\", \"HNRNPL\", \"IGF2BP1\", \"IGF2BP2\", \"IGF2BP3\", \"NSUN2\", \"PUM2\", \"SRSF1\", \"TIA1\")\n",
    "RBPS=(\"EWSR1\",)\n",
    "num_data = {}\n",
    "for RBP in RBPS:\n",
    "    #MASTER_DIR = \"./datasets\"\n",
    "    MASTER_DIR = \"./sample_dataset\"\n",
    "    heads = heads_all[RBP]\n",
    "    rbps= [RBP] * len(heads)\n",
    "    regiontypes = (\"5'UTR\", \"3'UTR\", \"exon\", \"intron\", \"CDS\", \"outside\")\n",
    "    regionboundaries = [[1,4],[0,4],[3,4],[0,3],[1,3]]\n",
    "    SUBDIR = \"finetuned_model/analyze_regionboundary\"\n",
    "    tsv_file_original = \"analyze_regionboundary_specific_all_layer{}_head{}.tsv\"\n",
    "    selected_heads = []\n",
    "    NUM_SPLIT = 3\n",
    "    VOLUME_PERCENT = 0.995\n",
    "\n",
    "    ax_i = 1#len(rbps)\n",
    "    #if ax_i < 2:\n",
    "    #    ax_i = 2\n",
    "    ax_j = len(regionboundaries)\n",
    "    heatmap_xlabels = list(map(int, np.linspace(1,12,12)))\n",
    "    heatmap_ylabels = heatmap_xlabels[::-1]\n",
    "\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\", {'grid.linestyle': '-'})\n",
    "    sns.despine()\n",
    "\n",
    "    for num_rbp, rbp in enumerate(rbps):\n",
    "        fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*8, ax_i*6))\n",
    "        filename = os.path.join(MASTER_DIR, rbp, SUBDIR, tsv_file_original.format(heads[num_rbp][0], heads[num_rbp][1]))\n",
    "        df_data = pd.read_csv(filename, sep=\"\\t\")\n",
    "        print(rbp)\n",
    "        if num_rbp == 0:\n",
    "            num_data[RBP] = len(df_data)\n",
    "\n",
    "        num_bins= 15\n",
    "        q_low = 0\n",
    "        q_high = VOLUME_PERCENT\n",
    "        quantiles = df_data[df_data[\"regiontype\"]!=\"outside\"][\"attention\"].quantile([q_low, q_high])\n",
    "        attention_max = quantiles[q_high]\n",
    "        attention_min = quantiles[q_low]\n",
    "        attention_thresh = np.linspace(attention_min, attention_max, num_bins+1)\n",
    "\n",
    "        counts = np.zeros([NUM_SPLIT, len(regionboundaries), num_bins])\n",
    "        fracs = np.linspace(0,1,NUM_SPLIT+1) * len(df_data)\n",
    "        fracs = list(map(int, fracs))\n",
    "        for num_split, frac in enumerate(fracs[1:]):\n",
    "            frac = frac - fracs[num_split]\n",
    "            count = np.zeros([len(regionboundaries), num_bins])\n",
    "            len_df_data = len(df_data)\n",
    "            df_data_split = 0\n",
    "            if num_split==NUM_SPLIT-1:\n",
    "                df_data_split = df_data\n",
    "            else:\n",
    "                df_data_split = df_data.sample(n=frac, random_state=0)\n",
    "            df_data = df_data.drop(df_data_split.index)\n",
    "            df_data_split = np.array(df_data_split)\n",
    "            for i in range(1, len(attention_thresh)):\n",
    "                tmp1 = df_data_split[:, 1]\n",
    "                tmp2 = df_data_split[np.where(tmp1 > attention_thresh[i-1])]\n",
    "                tmp1 = tmp1[np.where(tmp1 > attention_thresh[i-1])]\n",
    "                tmp2 = tmp2[np.where(tmp1 <= attention_thresh[i])]\n",
    "                tmp1 = tmp2[:, 0]\n",
    "                for num_tmp, regionboundary in enumerate(regionboundaries):\n",
    "                    title = \"{}_and_{}\".format(regiontypes[regionboundary[0]], regiontypes[regionboundary[1]])\n",
    "                    if regionboundary[0]==-1:\n",
    "                        title = \"outside\"\n",
    "                    if len(tmp1) == 0:\n",
    "                        count[num_tmp, i-1] = len(np.where(tmp1==title)[0])\n",
    "                    else:\n",
    "                        count[num_tmp, i-1] = len(np.where(tmp1==title)[0]) / len(tmp1)\n",
    "            counts[num_split] = count\n",
    "        stds = np.std(counts, axis=0)\n",
    "        counts = np.mean(counts, axis=0)\n",
    "\n",
    "        filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regionboundary_count_all.npy\")\n",
    "        count_boundary = np.load(filename)\n",
    "        filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_regionboundary_count_negative_all.npy\")\n",
    "        count_boundary = count_boundary / (count_boundary + np.load(filename))\n",
    "\n",
    "        for num_boundary, regionboundary in enumerate(regionboundaries):\n",
    "            background_x = [attention_min, attention_max]\n",
    "            background_y = 0\n",
    "            if regionboundary[0]==-1:\n",
    "                background_y = [0,0]\n",
    "            else:\n",
    "                background_y = [count_boundary[num_boundary]] * 2\n",
    "\n",
    "            title = \"{}_and_{}\".format(regiontypes[regionboundary[0]], regiontypes[regionboundary[1]])\n",
    "            if regionboundary[0]==-1:\n",
    "                title = \"outside\"\n",
    "\n",
    "            y_value = counts[num_boundary]\n",
    "            if NUM_SPLIT==1:\n",
    "                ax[num_boundary].bar(attention_thresh[:-1], y_value, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")\n",
    "            else:\n",
    "                y_err = stds[num_boundary]\n",
    "                ax[num_boundary].bar(attention_thresh[:-1], y_value, yerr=y_err, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")\n",
    "            ax[num_boundary].set_xlabel(\"Raw attention to the boundary\", fontsize=18, labelpad=6)\n",
    "            ax[num_boundary].set_ylabel(\"Region boundary probability\", fontsize=18, labelpad=6)\n",
    "            ax[num_boundary].set_title(\"{} BERT-RBP\\nhead{}-{}: {}\".format(rbp, heads[num_rbp][0], heads[num_rbp][1], title), fontsize=20, x=0.5, y=1.03)\n",
    "            ax[num_boundary].plot(background_x, background_y, '--', label=\"background\", color=\"#475267\")\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.3, top=0.8)\n",
    "        fig.patch.set_alpha(0)\n",
    "        fig.savefig(\"graph_regionboundary_{}_head{}-{}.eps\".format(rbp, heads[num_rbp][0], heads[num_rbp][1]), dpi=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-coffee",
   "metadata": {},
   "source": [
    "### 6. Visualize RNA secondary structure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MASTER_DIR = \"./datasets\"\n",
    "MASTER_DIR = \"./sample_dataset\"\n",
    "MASTER_DIR_DNABERT = \"../3-new-12w-0/\"\n",
    "'''\n",
    "rbps=(\"RBM22\", \"HNRNPK\", \"EWSR1\", \"SRSF1\", \"SRSF9\",\\\n",
    "      \"TIA1\", \"TIAL1\", \"TAF15\", \"FUS\")\n",
    "'''\n",
    "rbps=(\"HNRNPK\",)\n",
    "rbps=sorted(rbps)\n",
    "structuretypes = (\"F(dangling start)\", \"T(dangling end)\", \"I(internal loop)\", \"H(hairpin loop)\", \"M(multi loop)\", \"S(stem)\")\n",
    "SUBDIR_ORIG = \"finetuned_model/analyze_rnastructure\"\n",
    "SUBDIR_DNABERT = \"analyze_rnastructure\"\n",
    "SUBDIR_ANNOT = \"nontraining_sample_finetune\"\n",
    "selected_heads = []\n",
    "\n",
    "ax_i = 2#len(rbps)\n",
    "#if ax_i < 2:\n",
    "#    ax_i = 2\n",
    "ax_j = len(structuretypes)\n",
    "heatmap_xlabels = list(map(int, np.linspace(1,12,12)))\n",
    "heatmap_ylabels = heatmap_xlabels[::-1]\n",
    "\n",
    "for num_rbp, rbp in enumerate(rbps):\n",
    "    fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*8, ax_i*6.4))\n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR_ORIG, \"analyze_rnastructure2.npy\")\n",
    "\n",
    "    #annotations = np.load(os.path.join(MASTER_DIR, rbp, SUBDIR_ANNOT, \"annotations.npy\"))\n",
    "    rnastructure_matrix = np.load(filename)\n",
    "    filename2 = os.path.join(MASTER_DIR_DNABERT, rbp, SUBDIR_DNABERT, \"analyze_rnastructure2.npy\")\n",
    "    if os.path.exists(filename2):\n",
    "        rnastructure_matrix2 = np.load(filename2)\n",
    "    \n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR_ORIG, \"analyze_rnastructure_count_type0.npy\")\n",
    "    counts = np.load(filename)\n",
    "    filename = os.path.join(MASTER_DIR, rbp, SUBDIR_ORIG, \"analyze_rnastructure_count_negative_type0.npy\")\n",
    "    counts = counts / (counts + np.load(filename))\n",
    "    \n",
    "    max_heads = []\n",
    "    for i in range(len(structuretypes)):\n",
    "        max_val = np.max(rnastructure_matrix[i])\n",
    "        max_heads.append((np.where(rnastructure_matrix[i]==max_val)[0][0]+1, np.where(rnastructure_matrix[i]==max_val)[1][0]+1))\n",
    "        sns.heatmap(np.flip(rnastructure_matrix[i], axis=0), ax =ax[0,i], \\\n",
    "                    cmap=\"bertrbp_single_bertrbp_seq\", center=counts[i])\n",
    "        ax[0,i].set_xlabel(\"head\")\n",
    "        ax[0,i].set_ylabel(\"layer\")\n",
    "        ax[0,i].set_xticklabels(heatmap_xlabels)\n",
    "        ax[0,i].set_yticklabels(heatmap_ylabels)\n",
    "        ax[0,i].set_title(\"{}: {}\".format(rbp, structuretypes[i]))\n",
    "        if os.path.exists(filename2):\n",
    "            sns.heatmap(np.flip(rnastructure_matrix2[i], axis=0), ax =ax[1,i], \\\n",
    "                        cmap=\"bertrbp_single_bertdnabert_seq\", center=counts[i])\n",
    "        ax[1,i].set_xlabel(\"head\")\n",
    "        ax[1,i].set_ylabel(\"layer\")\n",
    "        ax[1,i].set_xticklabels(heatmap_xlabels)\n",
    "        ax[1,i].set_yticklabels(heatmap_ylabels)\n",
    "        ax[1,i].set_title(\"{} DNABERT: {}\".format(rbp, structuretypes[i]))\n",
    "\n",
    "    fig.patch.set_alpha(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-reception",
   "metadata": {},
   "source": [
    "### 7. Visualize RNA secondary structure analysis (in detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-headquarters",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads_all = {\"EWSR1\": ((3, 4), (6, 9), (3, 3), (7, 12)),\n",
    "             \"FUS\": ((3, 4), (6, 9), (3, 5), (7, 12), (3, 3)), \n",
    "             \"HNRNPK\": ((6, 6), (6, 9), (3, 5), (7, 12)),\n",
    "             \"RBM22\": ((3, 4), (7, 5), (11, 1), (7, 12), (3, 3)),\n",
    "             \"SRSF1\": ((3, 4), (6, 9), (11, 6), (3, 5)),\n",
    "             \"SRSF9\": ((3, 4), (6, 9), (8, 2), (7, 7), (3, 3)),\n",
    "             \"TAF15\": ((3, 4), (6, 9), (3, 5), (3, 7), (7, 7), (3, 3)),\n",
    "             \"TIA1\": ((6, 6), (6, 9), (3, 5), (11, 1), (7, 7), (3, 3)),\n",
    "             \"TIAL1\": ((3, 4), (8, 8), (3, 8), (7, 10), (7, 7), (3, 3))}\n",
    "structuretypes = (\"F (dangling start)\", \"T (dangling end)\", \"I (internal loop)\", \"H (hairpin loop)\", \"M (multi loop)\", \"S (stem)\")\n",
    "#MASTER_DIR = \"./datasets\"\n",
    "MASTER_DIR = \"./sample_dataset\"\n",
    "#RBPS=('EWSR1', 'FUS', 'HNRNPK', 'RBM22', 'SRSF1', 'SRSF9', 'TAF15', 'TIA1', 'TIAL1')\n",
    "RBPS=('HNRNPK',)\n",
    "for RBP in RBPS:\n",
    "    heads = heads_all[RBP]\n",
    "    rbps = [RBP] * len(heads)\n",
    "    structuretypes = (\"F (dangling start)\", \"T (dangling end)\", \"I (internal loop)\", \"H (hairpin loop)\", \"M (multi loop)\", \"S (stem)\")\n",
    "    SUBDIR = \"finetuned_model/analyze_rnastructure\"\n",
    "    selected_heads = []\n",
    "    NUM_SPLIT = 3\n",
    "    VOLUME_PERCENT = 0.995\n",
    "\n",
    "    ax_i = 1\n",
    "    ax_j = len(structuretypes)\n",
    "    heatmap_xlabels = list(map(int, np.linspace(1,12,12)))\n",
    "    heatmap_ylabels = heatmap_xlabels[::-1]\n",
    "\n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\", {'grid.linestyle': '-'})\n",
    "    sns.despine()\n",
    "\n",
    "    for num_rbp, rbp in enumerate(rbps):\n",
    "        fig, ax = plt.subplots(ax_i, ax_j, figsize=(ax_j*7.5, ax_i*6))\n",
    "        filename = os.path.join(MASTER_DIR, rbp, SUBDIR, \"analyze_rnastructure_specific_layer{}_head{}.tsv\".format(heads[num_rbp][0], heads[num_rbp][1]))\n",
    "        df_data = pd.read_csv(filename, sep=\"\\t\")\n",
    "        print(rbp)\n",
    "\n",
    "        num_bins= 15\n",
    "        q_low = 0\n",
    "        q_high = VOLUME_PERCENT\n",
    "        quantiles = df_data[\"attention\"].quantile([q_low, q_high])\n",
    "        attention_max = quantiles[q_high]\n",
    "        attention_min = quantiles[q_low]\n",
    "        attention_thresh = np.linspace(attention_min, attention_max, num_bins+1)\n",
    "        background = np.zeros(len(structuretypes))\n",
    "        for structuretype in range(len(structuretypes)):\n",
    "            tmp1 = (df_data[\"structure\"] == float(structuretype))\n",
    "            background[structuretype] = tmp1.sum()\n",
    "        background = background / np.sum(background)\n",
    "\n",
    "        counts = np.zeros([NUM_SPLIT, len(structuretypes), num_bins])\n",
    "        fracs = np.linspace(0,1,NUM_SPLIT+1) * len(df_data)\n",
    "        fracs = list(map(int, fracs))\n",
    "        for num_split, frac in enumerate(fracs[1:]):\n",
    "            frac = frac - fracs[num_split]\n",
    "            count = np.zeros([len(structuretypes), num_bins])\n",
    "            len_df_data = len(df_data)\n",
    "            df_data_split = 0\n",
    "            if num_split==NUM_SPLIT-1:\n",
    "                df_data_split = df_data\n",
    "            else:\n",
    "                df_data_split = df_data.sample(n=frac, random_state=0)\n",
    "            df_data = df_data.drop(df_data_split.index)\n",
    "            df_data_split = np.array(df_data_split)\n",
    "            for i in range(1, len(attention_thresh)):\n",
    "                tmp1 = df_data_split[:, 1]\n",
    "                tmp2 = df_data_split[np.where(tmp1 > attention_thresh[i-1])]\n",
    "                tmp1 = tmp1[np.where(tmp1 > attention_thresh[i-1])]\n",
    "                tmp2 = tmp2[np.where(tmp1 <= attention_thresh[i])]\n",
    "                tmp1 = tmp2[:, 0]\n",
    "                for structuretype in range(len(structuretypes)):\n",
    "                    count[structuretype, i-1] = len(np.where(tmp1==structuretype)[0]) / len(tmp1)\n",
    "            counts[num_split] = count\n",
    "        stds = np.std(counts, axis=0)\n",
    "        counts = np.mean(counts, axis=0)\n",
    "\n",
    "        for num_structure, structure in enumerate(structuretypes):\n",
    "            background_x = [attention_min, attention_max]\n",
    "            background_y = [background[num_structure]] * 2\n",
    "\n",
    "            y_value = counts[num_structure]\n",
    "            if NUM_SPLIT==1:\n",
    "                ax[num_structure].bar(attention_thresh[:-1], y_value, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")\n",
    "            else:\n",
    "                y_err = stds[num_structure]\n",
    "                ax[num_structure].bar(attention_thresh[:-1], y_value, yerr=y_err, width=(attention_max-attention_min)*0.05, align=\"edge\", color=\"#e69166\")\n",
    "\n",
    "            ax[num_structure].set_xlabel(\"Raw attention to the structure\", fontsize=18, labelpad=6)\n",
    "            ax[num_structure].set_ylabel(\"Structure probability\", fontsize=18, labelpad=6)\n",
    "            ax[num_structure].set_title(\"{} BERT-RBP\\nhead{}-{}: {}\".format(rbp, heads[num_rbp][0], heads[num_rbp][1], structuretypes[num_structure]), fontsize=20, x=0.5, y=1.03)\n",
    "            ax[num_structure].plot(background_x, background_y, '--', label=\"background\", color=\"#475267\")\n",
    "            \n",
    "        fig.subplots_adjust(top=0.8)\n",
    "        fig.patch.set_alpha(0)\n",
    "        fig.savefig(\"graph_2dstructure_{}_head{}-{}.eps\".format(rbp, heads[num_rbp][0], heads[num_rbp][1]), dpi=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-state",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
